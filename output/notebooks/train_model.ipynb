{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bfe55a",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9d413d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T20:05:13.432781Z",
     "iopub.status.busy": "2022-03-20T20:05:13.432486Z",
     "iopub.status.idle": "2022-03-20T20:05:13.439818Z",
     "shell.execute_reply": "2022-03-20T20:05:13.439259Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.01748,
     "end_time": "2022-03-20T20:05:13.441815",
     "exception": false,
     "start_time": "2022-03-20T20:05:13.424335",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2714e355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T20:05:13.452175Z",
     "iopub.status.busy": "2022-03-20T20:05:13.451958Z",
     "iopub.status.idle": "2022-03-20T20:05:13.455082Z",
     "shell.execute_reply": "2022-03-20T20:05:13.454461Z"
    },
    "papermill": {
     "duration": 0.01017,
     "end_time": "2022-03-20T20:05:13.456911",
     "exception": false,
     "start_time": "2022-03-20T20:05:13.446741",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "product = {\n",
    "    \"nb\": \"/Users/aiujdm2/market_watch/output/notebooks/train_model.ipynb\",\n",
    "    \"model\": \"/Users/aiujdm2/market_watch/output/models/model.pkl\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36befe4",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e089578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T20:05:13.466513Z",
     "iopub.status.busy": "2022-03-20T20:05:13.466311Z",
     "iopub.status.idle": "2022-03-20T20:05:23.744082Z",
     "shell.execute_reply": "2022-03-20T20:05:23.743301Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 10.283986,
     "end_time": "2022-03-20T20:05:23.745303",
     "exception": true,
     "start_time": "2022-03-20T20:05:13.461317",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aiujdm2/.local/share/virtualenvs/market_watch-dtlP-L11/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'environ' from 'src.models' (/Users/aiujdm2/market_watch/src/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mignite\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Engine\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mignite\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontrib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhandlers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorboard_logger \u001B[38;5;28;01mas\u001B[39;00m tb_logger\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m environ, data, models, common, validation\n\u001B[1;32m     14\u001B[0m SAVES_DIR \u001B[38;5;241m=\u001B[39m pathlib\u001B[38;5;241m.\u001B[39mPath(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaves\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m STOCKS \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/raw/YNDX_160101_161231.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'environ' from 'src.models' (/Users/aiujdm2/market_watch/src/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "import ptan\n",
    "import pathlib\n",
    "import gym.wrappers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from ignite.engine import Engine\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger\n",
    "\n",
    "from src.models import environ, data, models, common, validation\n",
    "\n",
    "SAVES_DIR = pathlib.Path(\"saves\")\n",
    "STOCKS = \"data/raw/YNDX_160101_161231.csv\"\n",
    "VAL_STOCKS = \"data/raw/YNDX_150101_151231.csv\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BARS_COUNT = 10\n",
    "\n",
    "EPS_START = 1.0\n",
    "EPS_FINAL = 0.1\n",
    "EPS_STEPS = 1000000\n",
    "\n",
    "GAMMA = 0.99\n",
    "\n",
    "REPLAY_SIZE = 100000\n",
    "REPLAY_INITIAL = 10000\n",
    "REWARD_STEPS = 2\n",
    "LEARNING_RATE = 0.0001\n",
    "STATES_TO_EVALUATE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f93bf4",
   "metadata": {
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "cuda = False\n",
    "# parser.add_argument(\"--data\", default=STOCKS, help=f\"Stocks file or dir, default={STOCKS}\")\n",
    "# parser.add_argument(\"--year\", type=int, help=\"Year to train on, overrides --data\")\n",
    "year = '2016'\n",
    "# parser.add_argument(\"--val\", default=VAL_STOCKS, help=\"Validation data, default=\" + VAL_STOCKS)\n",
    "val = VAL_STOCKS\n",
    "# parser.add_argument(\"-r\", \"--run\", required=False, help=\"Run name\")\n",
    "run = 'test'\n",
    "# args = parser.parse_args()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "saves_path = SAVES_DIR / f\"conv-{run}\"\n",
    "saves_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path = pathlib.Path(STOCKS)\n",
    "val_path = pathlib.Path(val)\n",
    "\n",
    "if year is not None or data_path.is_file():\n",
    "    if year is not None:\n",
    "        stock_data = data.load_year_data(year, 'data/raw')\n",
    "    else:\n",
    "        stock_data = {\"YNDX\": data.load_relative(data_path)}\n",
    "    env = environ.StocksEnv(stock_data, bars_count=BARS_COUNT, state_1d=True)\n",
    "    env_tst = environ.StocksEnv(stock_data, bars_count=BARS_COUNT, state_1d=True)\n",
    "elif data_path.is_dir():\n",
    "    env = environ.StocksEnv.from_dir(data_path, bars_count=BARS_COUNT, state_1d=True)\n",
    "    env_tst = environ.StocksEnv.from_dir(data_path, bars_count=BARS_COUNT, state_1d=True)\n",
    "else:\n",
    "    raise RuntimeError(\"No data to train on\")\n",
    "\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=1000)\n",
    "val_data = {\"YNDX\": data.load_relative(val_path)}\n",
    "env_val = environ.StocksEnv(val_data, bars_count=BARS_COUNT, state_1d=True)\n",
    "\n",
    "net = models.DQNConv1D(env.observation_space.shape, env.action_space.n).to(device)\n",
    "tgt_net = ptan.agent.TargetNet(net)\n",
    "\n",
    "selector = ptan.actions.EpsilonGreedyActionSelector(EPS_START)\n",
    "eps_tracker = ptan.actions.EpsilonTracker(\n",
    "    selector, EPS_START, EPS_FINAL, EPS_STEPS)\n",
    "agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "    env, agent, GAMMA, steps_count=REWARD_STEPS)\n",
    "buffer = ptan.experience.ExperienceReplayBuffer(\n",
    "    exp_source, REPLAY_SIZE)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def process_batch(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    loss_v = common.calc_loss(\n",
    "        batch, net, tgt_net.target_model,\n",
    "        gamma=GAMMA ** REWARD_STEPS, device=device)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    eps_tracker.frame(engine.state.iteration)\n",
    "\n",
    "    if getattr(engine.state, \"eval_states\", None) is None:\n",
    "        eval_states = buffer.sample(STATES_TO_EVALUATE)\n",
    "        eval_states = [np.array(transition.state, copy=False)\n",
    "                        for transition in eval_states]\n",
    "        engine.state.eval_states = np.array(eval_states, copy=False)\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss_v.item(),\n",
    "        \"epsilon\": selector.epsilon,\n",
    "    }\n",
    "\n",
    "engine = Engine(process_batch)\n",
    "tb = common.setup_ignite(engine, exp_source, f\"conv-{run}\",\n",
    "                            extra_metrics=('values_mean',))\n",
    "\n",
    "@engine.on(ptan.ignite.PeriodEvents.ITERS_1000_COMPLETED)\n",
    "def sync_eval(engine: Engine):\n",
    "    tgt_net.sync()\n",
    "\n",
    "    mean_val = common.calc_values_of_states(\n",
    "        engine.state.eval_states, net, device=device)\n",
    "    engine.state.metrics[\"values_mean\"] = mean_val\n",
    "    if getattr(engine.state, \"best_mean_val\", None) is None:\n",
    "        engine.state.best_mean_val = mean_val\n",
    "    if engine.state.best_mean_val < mean_val:\n",
    "        print(\"%d: Best mean value updated %.3f -> %.3f\" % (\n",
    "            engine.state.iteration, engine.state.best_mean_val,\n",
    "            mean_val))\n",
    "        path = saves_path / (\"mean_value-%.3f.data\" % mean_val)\n",
    "        torch.save(net.state_dict(), path)\n",
    "        engine.state.best_mean_val = mean_val\n",
    "\n",
    "@engine.on(ptan.ignite.PeriodEvents.ITERS_10000_COMPLETED)\n",
    "def validate(engine: Engine):\n",
    "    res = validation.validation_run(env_tst, net, device=device)\n",
    "    print(\"%d: tst: %s\" % (engine.state.iteration, res))\n",
    "    for key, val in res.items():\n",
    "        engine.state.metrics[key + \"_tst\"] = val\n",
    "    res = validation.validation_run(env_val, net, device=device)\n",
    "    print(\"%d: val: %s\" % (engine.state.iteration, res))\n",
    "    for key, val in res.items():\n",
    "        engine.state.metrics[key + \"_val\"] = val\n",
    "    val_reward = res['episode_reward']\n",
    "    if getattr(engine.state, \"best_val_reward\", None) is None:\n",
    "        engine.state.best_val_reward = val_reward\n",
    "    if engine.state.best_val_reward < val_reward:\n",
    "        print(\"Best validation reward updated: %.3f -> %.3f, model saved\" % (\n",
    "            engine.state.best_val_reward, val_reward\n",
    "        ))\n",
    "        engine.state.best_val_reward = val_reward\n",
    "        path = saves_path / (\"val_reward-%.3f.data\" % val_reward)\n",
    "        torch.save(net.state_dict(), path)\n",
    "\n",
    "\n",
    "event = ptan.ignite.PeriodEvents.ITERS_10000_COMPLETED\n",
    "tst_metrics = [m + \"_tst\" for m in validation.METRICS]\n",
    "tst_handler = tb_logger.OutputHandler(\n",
    "    tag=\"test\", metric_names=tst_metrics)\n",
    "tb.attach(engine, log_handler=tst_handler, event_name=event)\n",
    "\n",
    "val_metrics = [m + \"_val\" for m in validation.METRICS]\n",
    "val_handler = tb_logger.OutputHandler(\n",
    "    tag=\"validation\", metric_names=val_metrics)\n",
    "tb.attach(engine, log_handler=val_handler, event_name=event)\n",
    "\n",
    "engine.run(common.batch_generator(buffer, REPLAY_INITIAL, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a646554",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "duration": 11.670609,
   "end_time": "2022-03-20T20:05:24.169303",
   "exception": true,
   "input_path": "/var/folders/b0/4tc1nfbd6z7_vhx4nxcj2n91c0l9h6/T/tmp1xdxobr4.ipynb",
   "output_path": "/Users/aiujdm2/market_watch/output/notebooks/train_model.ipynb",
   "parameters": {
    "product": {
     "model": "/Users/aiujdm2/market_watch/output/models/model.pkl",
     "nb": "/Users/aiujdm2/market_watch/output/notebooks/train_model.ipynb"
    }
   },
   "start_time": "2022-03-20T20:05:12.498694"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}